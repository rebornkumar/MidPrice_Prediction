{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathon_MidPrice_Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download zip file to local drive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#[DONOTCHANGE]\n",
    "#1st step - Download files from Google drive\n",
    "#Manual download from https://drive.google.com/open?id=1lExwruiCpiOwgE_ijiZ1l6sIYbHnt5v_\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "def DownloadZipFiles():\n",
    "  print('Download zip file to local drive')\n",
    "  !rm -rf intraday.zip\n",
    "  !rm -rf intraday\n",
    "  urllib.request.urlretrieve(\"https://drive.google.com/uc?authuser=0&id=1lExwruiCpiOwgE_ijiZ1l6sIYbHnt5v_&export=download\", \"intraday.zip\")  \n",
    "  !unzip intraday.zip -d .\n",
    "\n",
    "def FilesExists():\n",
    "  if not os.path.exists('./intraday'):\n",
    "    return False\n",
    "  fileList = ['quote_in.csv', 'quote_out.csv', 'trade_in.csv', 'trade_out.csv']\n",
    "  listDir = os.listdir('./intraday')\n",
    "  listDir.sort()\n",
    "  return listDir == fileList\n",
    "\n",
    "try:    \n",
    "  if not FilesExists():\n",
    "    DownloadZipFiles()\n",
    "  else:\n",
    "    print('Files exist')    \n",
    "except Exception as ex:\n",
    "  print('File download from google drive failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install pandas\\n!pip install pytz\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2nd step - Install all required libraries\n",
    "\"\"\"\n",
    "!pip install pandas\n",
    "!pip install pytz\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[DONOTCHANGE]\n",
    "#3rd step - all parameters\n",
    "class Parameters(object):\n",
    "    pass\n",
    "\n",
    "param = Parameters()\n",
    "param.tickSize = 0.5 #tick size is 0.5 GBp i.e. 0.005 GBP\n",
    "\n",
    "param.fileDirectory = './intraday'\n",
    "\n",
    "param.trade_InSampleFile = 'trade_in.csv'\n",
    "param.quote_InSampleFile = 'quote_in.csv'\n",
    "\n",
    "param.trade_OutSampleFile = 'trade_out.csv'\n",
    "param.quote_OutSampleFile = 'quote_out.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4th step - Model specific parameters\n",
    "param.imbalanceThreshold = 0.7\n",
    "param.timeDuration = 30 #30 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise libraries and functions\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import datasets, linear_model\n",
    "from math import sqrt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "#Disable certain warnings\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INNCOMMING DATAFRAME HAS\n",
    "# colunms=['datetime','sym',ask','bid','asize','bsize','mid','midChangeGroup']  #\n",
    "def IdentifyFutureMidPrices(df,predictionDuration = '30S'):\n",
    "   \n",
    " # downSampling by 30seconds#\n",
    "    futureData = df.resample(predictionDuration, on = 'datetime').first()\n",
    "    \n",
    "# shiftup by one index #\n",
    "    futureData = futureData.shift(periods=-1)\n",
    "    \n",
    "# drop all columns but mid and preMid and inplace\n",
    "    futureData.drop(columns = ['datetime', 'sym', 'bsize', 'bid', 'ask', 'asize'], inplace = True)\n",
    "    \n",
    "# rename column \"mid\" as \"futMid\" #\n",
    "    futureData.rename(columns = {\"mid\":\"futMid\"}, inplace = True)\n",
    "    \n",
    "# reset the index,inplace #\n",
    "    futureData.reset_index(inplace = True)\n",
    "    \n",
    "# This is similar to a left-join except that we match on nearest key rather than equal keys. #\n",
    "    return pd.merge_asof(df, futureData[['datetime', 'futMid']], on='datetime')\n",
    "\n",
    "# OUTGOING DATAFRAME HAS \n",
    "# colunms=['datetime','sym_X','sym_Y',ask','bid','asize','bsize',futMid','midChangeGroup']  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method reads CSV file and returns pandas DataFrame object\n",
    "def ReadCSV(file):\n",
    "    print('Loading file - ' + file)\n",
    "    df = pd.read_csv(file)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format=\"%Y-%m-%dD%H:%M:%S.%f\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "def LoadData(path, tradeFile, quoteFile):\n",
    "    tradeFile = os.path.join(path, tradeFile)\n",
    "    quoteFile = os.path.join(path, quoteFile)\n",
    "    \n",
    "# CSV to DataFrame #\n",
    "# colunms=['datetime','sym',ask','bid','asize','bsize']  #\n",
    "    quote_df = ReadCSV(quoteFile)\n",
    "    \n",
    "# colunms=['datetime','sym','price','size']  #\n",
    "    trade_df = ReadCSV(tradeFile)\n",
    "    \n",
    "# adding \"mid\" column to DataFrame #\n",
    "    quote_df['mid'] = 0.5*(quote_df['bid'].copy() + quote_df['ask'].copy())\n",
    "    \n",
    "# adding \"midChangeGroup\" column to DataFrame #\n",
    "# cumulative sum of changes in \"mid\" column of DataFrame #\n",
    "    quote_df['midChangeGroup'] = quote_df['mid'].diff().ne(0).cumsum()\n",
    "   \n",
    "    quote_df = IdentifyFutureMidPrices(quote_df)\n",
    "    print('Files loaded')\n",
    "    \n",
    "    return trade_df, quote_df\n",
    "# colunms=['datetime','sym',ask','bid','asize','bsize','mid,'futMid','midChangeGroup']  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCOMING DATAFRAME HAS \n",
    "# colunms=['datetime','sym',ask','bid','asize','bsize','futMid','midChangeGroup','predMid']  #\n",
    "\n",
    "# this method calculates the root mean square error\n",
    "def RMS(df):\n",
    "    df = df.groupby(['midChangeGroup']).first().reset_index()\n",
    "    tmp = df.dropna(subset=['predMid', 'futMid'])\n",
    "    rms = sqrt(mean_squared_error(tmp['futMid'], tmp['predMid']))\n",
    "    predCount = len(tmp['predMid'])\n",
    "    print('RMS = %.4f. #Predictions = %s' % (rms, predCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCOMING DATAFRAME HAS \n",
    "# colunms=['datetime','sym',ask','bid','asize','bsize','futMid','midChangeGroup']  #\n",
    "\n",
    "def InSamplePredictionModel(quote_df, trade_df):\n",
    "#Load pickle to predict\n",
    "    \n",
    "    pickleModel = open('Model.pkl','rb')\n",
    "    Model = pickle.load(pickleModel)\n",
    "    print('Prediction model') \n",
    "    \n",
    "# adding new features \"spread\",\"microMid\" to the model\n",
    "    quote_df['spread']=quote_df['bid'].copy()-quote_df['ask'].copy()\n",
    "    quote_df['microMid']=(quote_df['bid'].copy()*quote_df['bsize'].copy()+quote_df['ask'].copy()*quote_df['asize'].copy()) /(quote_df.copy()['bsize']+quote_df['asize'].copy())\n",
    "\n",
    "# Now merging quote_df and trade_df \n",
    "    Z=pd.merge_asof(quote_df,trade_df,on ='datetime')\n",
    "# dropping NaN values from DataFrame\n",
    "    Z.dropna(axis=0,how='any',inplace = True)\n",
    "# resetting the DataFrame index\n",
    "    Z.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# selecting features and labels from DataFrame\n",
    "# X_test -->features,Y_test-->label\n",
    "\n",
    "    X_test=Z.as_matrix(columns=['ask','bid','asize','bsize','midChangeGroup','size','price','mid','microMid','spread'])\n",
    "    Y_test=Z.as_matrix(columns=['futMid'])\n",
    "    \n",
    "# predicting values as trainned Model\n",
    "    pred=Model.predict(X_test)\n",
    "# new column \"predMid\" added to DataFrame\n",
    "    Z['predMid']=pred\n",
    "    \n",
    "    return Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV if not in memory\n",
    "dirContents = dir()\n",
    "if not ('tradeIndf' in dirContents and 'quoteIndf' in dirContents):\n",
    "    tradeIndf, quoteIndf = LoadData(param.fileDirectory, param.trade_InSampleFile, param.quote_InSampleFile)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranning Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MachineLearningModel(quote_df, trade_df):\n",
    "# adding new features \"spread\",\"microMid\" to the model\n",
    "    quote_df['spread']=quote_df['bid'].copy()-quote_df['ask'].copy()\n",
    "    quote_df['microMid']=(quote_df['bid'].copy()*quote_df['bsize'].copy()+quote_df['ask'].copy()*quote_df['asize'].copy()) /(quote_df.copy()['bsize']+quote_df['asize'].copy())\n",
    "\n",
    "# Now merging quote_df and trade_df \n",
    "    Z=pd.merge_asof(quote_df,trade_df,on ='datetime')\n",
    "# dropping NaN values from DataFrame\n",
    "    Z.dropna(axis=0,how='any',inplace = True)\n",
    "# resetting the DataFrame index\n",
    "    Z.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "# selecting features and labels from DataFrame\n",
    "# X_test -->features,Y_test-->label\n",
    "    X_train=Z.as_matrix(columns=['ask','bid','asize','bsize','midChangeGroup','size','price','mid','microMid','spread'])\n",
    "    Y_train=Z.as_matrix(columns=['futMid'])\n",
    "    \n",
    "# Using LinearRegression we train model\n",
    "    Model=linear_model.LinearRegression()\n",
    "    Model.fit(X_train,Y_train)\n",
    "    # pickle file\n",
    "    tempPickle = 'Model.pkl'\n",
    "    pickleModel= open(tempPickle,'wb')\n",
    "    pickle.dump(Model,pickleModel)\n",
    "    pickleModel.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As model has been trained using InSample Files and saved as \"Model.pkl\" file.No need to  Train Model using InSample file again and again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranning the model using InSample Files\n",
    "# we can comment this line if you don't want to use Insample File again\n",
    "MachineLearningModel(quoteIndf,tradeIndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the out-sample csv if not in memory\n",
    "dirContents = dir()\n",
    "if not ('tradeOutdf' in dirContents and 'quoteOutdf' in dirContents):\n",
    "    tradeOutdf, quoteOutdf = LoadData(param.fileDirectory, param.trade_OutSampleFile, param.quote_OutSampleFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicts the value for OutSample Files\n",
    "def OutSamplePrediction(quote_df, trade_df): \n",
    "    print('Out-sample prediction')    \n",
    "    return InSamplePredictionModel(quote_df, trade_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-sample prediction\n",
      "Prediction model\n",
      "RMS = 2.2354. #Predictions = 53135\n"
     ]
    }
   ],
   "source": [
    "# calculating Root Mean Square Error\n",
    "res = OutSamplePrediction(quoteOutdf, tradeOutdf)\n",
    "RMS(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this problem we have to predict future midPrice of the stock using historical data.So this problem fall in the category of continuous analysis.\n",
    "### As data is given in CSV format so no much of cleaning and formatting of data is required,it is ready to use format.\n",
    "### The data of the stock market given follows the linear relationship. This can be depiced by observing the visual plotting of the data. From the plotted graph, we can conclude that the regressors following the linear model are the best models that can be fitted.\n",
    "### Some new features are created in the data which can be very help in predicting the future values.\n",
    "### Scikit Learn library provides the machine learning models and also various functions for calculation related to it. \n",
    "### It provides a function to check the performance of different regressors that can be fit as the model. So using that Linear Regressor was performing best over the given data. \n",
    "### SGD Regressor can be used as the training set is quite large but it was lacking in performance. So Linear Regressor was the best fit midel for this system.\n",
    "# Prediction model\n",
    "## RMS = 2.2354\n",
    "## Predictions = 53135"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# happy Hackathon!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
